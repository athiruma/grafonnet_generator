
name: Deploy Perf Env Nightly CI

on:
  push:
    branches: [ "main" ]
  workflow_dispatch:

jobs:
  workload:
    name: workload
    runs-on: ubuntu-latest
    outputs:
      job_status: ${{ steps.job_step.outputs.status }}
    needs: initialize_nightly
    strategy:
       # run one job every time
       max-parallel: 1
       # continue to next job if failed
       fail-fast: false
       matrix:
          workload:
              - 'uperf_pod'
              - 'uperf_kata'
              - 'uperf_vm'
              - 'hammerdb_pod_mariadb'
              - 'hammerdb_kata_mariadb'
              - 'hammerdb_vm_mariadb'
              - 'hammerdb_pod_postgres'
              - 'hammerdb_kata_postgres'
              - 'hammerdb_vm_postgres'
              - 'hammerdb_pod_postgres_lso'
              - 'hammerdb_kata_postgres_lso'
              - 'hammerdb_vm_postgres_lso'
              - 'hammerdb_pod_mssql'
              - 'hammerdb_kata_mssql'
              - 'hammerdb_vm_mssql'
              - 'vdbench_pod'
              - 'vdbench_kata'
              - 'vdbench_vm'
              - 'vdbench_pod_scale'
              - 'vdbench_kata_scale'
              - 'vdbench_vm_scale'
              - 'clusterbuster'
              - 'bootstorm_vm_scale'
              - 'windows_vm_scale_windows10'
              - 'windows_vm_scale_windows11'
              - 'windows_vm_scale_windows_server_2019'
              - 'windows_vm_scale_windows_server_2022'

    steps:
    - uses: actions/checkout@v3
    - name: Set up Python 3.10
      uses: actions/setup-python@v4
      with:
        python-version: '3.10'
    - name: ✔️ Run workload ${{ matrix.workload }}
      run: |
        build=$(pip freeze | grep benchmark-runner | sed 's/==/=/g')
        build_version="$(cut -d'=' -f2 <<<"$build")"
        echo '>>>>>>>>>>>>>>>>>>>>>>>>>> Start E2E workload: ${{ matrix.workload }} >>>>>>>>>>>>>>>>>>>>>>>>>>'
        scp -r "$RUNNER_PATH/.kube/config" provision:"$CONTAINER_KUBECONFIG_PATH"
        workload=$(awk -F_ '{print $1"_"$2}' <<< '${{ matrix.workload }}')
        run=$(awk -F_ '{print $3}' <<< '${{ matrix.workload }}')
        echo 'run: $run'
        echo 'workload: $workload'
        # SCALE RUN
        if [[ '$run' == 'scale' ]]
        then
            echo SCALE
            # bootstorm_vm_scale: no need redis for synchronization but need SCALE and THREADS_LIMIT
            if [[ '${{ matrix.workload }}' == 'bootstorm_vm_scale' ]]
            then
              # Warm-up: Pull the Fedora image from quay.io for each node
              echo '$run'
            elif [[ '$workload' == 'windows_vm' ]]
            then
              case '${{ matrix.workload }}' in
                   'windows_vm_scale_windows10') WINDOWS_URL=$workload ;;
                   'windows_vm_scale_windows11') WINDOWS_URL=$workload ;;
                   'windows_vm_scale_windows_server_2019') WINDOWS_URL=$workload ;;
                   'windows_vm_scale_windows_server_2022') WINDOWS_URL=$workload ;;
                    *) echo "Unknown Windows scale workload ${{ matrix.workload }}"; exit 1 ;;
              esac
            fi
            # SCALE_NODES is a list, not add ''
            echo ssh -t provision "podman run --rm -t -e WORKLOAD='$workload' -e KUBEADMIN_PASSWORD='$KUBEADMIN_PASSWORD' -e SCALE='$SCALE' -e SCALE_NODES=$SCALE_NODES -e REDIS='$REDIS' -e PIN_NODE_BENCHMARK_OPERATOR='$PIN_NODE_BENCHMARK_OPERATOR' -e PIN_NODE1='$PIN_NODE1' -e PIN_NODE2='$PIN_NODE2' -e ELASTICSEARCH='$ELASTICSEARCH' -e ELASTICSEARCH_PORT='$ELASTICSEARCH_PORT' -e ELASTICSEARCH_USER='$ELASTICSEARCH_USER' -e ELASTICSEARCH_PASSWORD='$ELASTICSEARCH_PASSWORD' -e IBM_REGION_NAME='$IBM_REGION_NAME' -e IBM_ENDPOINT_URL='$IBM_ENDPOINT_URL' -e IBM_ACCESS_KEY_ID='$IBM_ACCESS_KEY_ID' -e IBM_SECRET_ACCESS_KEY='$IBM_SECRET_ACCESS_KEY' -e IBM_BUCKET='$IBM_BUCKET' -e IBM_KEY='$IBM_KEY' -e RUN_ARTIFACTS_URL='$RUN_ARTIFACTS_URL' -e BUILD_VERSION='$build_version' -e RUN_TYPE='$RUN_TYPE' -e KATA_CPUOFFLINE_WORKAROUND='True' -e SAVE_ARTIFACTS_LOCAL='False' -e ENABLE_PROMETHEUS_SNAPSHOT='$ENABLE_PROMETHEUS_SNAPSHOT' -e THREADS_LIMIT='$THREADS_LIMIT' -e WINDOWS_URL='$WINDOWS_URL' -e TIMEOUT='$TIMEOUT' -e log_level='INFO' -v '$CONTAINER_KUBECONFIG_PATH':'$CONTAINER_KUBECONFIG_PATH' --privileged 'quay.io/ebattat/benchmark-runner:latest'"
        # NOT SCALE RUN
        else
            if [[ '${{ matrix.workload }}' == 'clusterbuster' ]]
            then
              # clusterbuster: disable prometheus logs
              echo ENABLE_PROMETHEUS_SNAPSHOT='False'
            fi
            if [[ '${{ matrix.workload }}' == 'vdbench_vm' ]]
            then
              # Warm-up: download vdbench_vm container disk image per node (centos stream8)
              echo ssh -t provision "podman run --rm -t -e WORKLOAD='${{ matrix.workload }}' -e KUBEADMIN_PASSWORD='$KUBEADMIN_PASSWORD' -e SCALE='$SCALE' -e SCALE_NODES=$SCALE_NODES -e REDIS='$REDIS' -e RUN_TYPE='test_ci' -e SAVE_ARTIFACTS_LOCAL='False' -e THREADS_LIMIT='$THREADS_LIMIT' -e TIMEOUT='$TIMEOUT' -e log_level='INFO' -v '$CONTAINER_KUBECONFIG_PATH':'$CONTAINER_KUBECONFIG_PATH' --privileged 'quay.io/ebattat/benchmark-runner:latest'"
            fi
            echo ssh -t provision "podman run --rm -t -e WORKLOAD='${{ matrix.workload }}' -e KUBEADMIN_PASSWORD='$KUBEADMIN_PASSWORD' -e PIN_NODE_BENCHMARK_OPERATOR='$PIN_NODE_BENCHMARK_OPERATOR' -e PIN_NODE1='$PIN_NODE1' -e PIN_NODE2='$PIN_NODE2' -e ELASTICSEARCH='$ELASTICSEARCH' -e ELASTICSEARCH_PORT='$ELASTICSEARCH_PORT' -e ELASTICSEARCH_USER='$ELASTICSEARCH_USER' -e ELASTICSEARCH_PASSWORD='$ELASTICSEARCH_PASSWORD' -e IBM_REGION_NAME='$IBM_REGION_NAME' -e IBM_ENDPOINT_URL='$IBM_ENDPOINT_URL' -e IBM_ACCESS_KEY_ID='$IBM_ACCESS_KEY_ID' -e IBM_SECRET_ACCESS_KEY='$IBM_SECRET_ACCESS_KEY' -e IBM_BUCKET='$IBM_BUCKET' -e IBM_KEY='$IBM_KEY' -e RUN_ARTIFACTS_URL='$RUN_ARTIFACTS_URL' -e BUILD_VERSION='$build_version' -e RUN_TYPE='$RUN_TYPE' -e KATA_CPUOFFLINE_WORKAROUND='True' -e SAVE_ARTIFACTS_LOCAL='False' -e ENABLE_PROMETHEUS_SNAPSHOT='$ENABLE_PROMETHEUS_SNAPSHOT' -e WORKER_DISK_IDS=$WORKER_DISK_IDS -e WORKER_DISK_PREFIX='$WORKER_DISK_PREFIX' -e TIMEOUT='$TIMEOUT' -e log_level='INFO' -v '$CONTAINER_KUBECONFIG_PATH':'$CONTAINER_KUBECONFIG_PATH' --privileged 'quay.io/ebattat/benchmark-runner:latest'"
        fi
